{"cells": [{"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+--------------+-----------+--------------+---------+---------+\n| ID|CHAVE_SITUACAO|CLASS_RISCO|   CAT_CLIENTE|PAGAMENTO|CATEGORIA|\n+---+--------------+-----------+--------------+---------+---------+\n|  1|          32FC|      cinza|   Basic-Alpha|        1|        C|\n|  2|          25MV|    Amarelo|         Black|        1|        A|\n|  3|          27MV|    Amarelo|    Basic-Beta|        1|        B|\n|  4|          26FD|    Amarelo|         Black|        0|        B|\n|  5|          26FD|    Amarelo|         Black|        0|        C|\n|  6|          28FC|    Amarelo|Platinum-Alpha|        0|        C|\n|  7|          27MD|      Verde| Platinum-Beta|        1|        A|\n|  8|          31MD|      Cinza|         Basic|        0|        C|\n|  9|          28FS|      Cinza|         Black|        1|        A|\n| 10|          31MV|    Amarelo|      Platinum|        1|        C|\n| 11|          29MV|    Amarelo|         Basic|        1|        A|\n| 12|          30FC|      Cinza|    Basic-Beta|        0|        C|\n| 13|          28FC|      verde|         Basic|        0|        B|\n| 14|          26MC|      Verde|      Platinum|        1|        A|\n| 15|          26MC|       roxo|   Black-Alpha|        1|        C|\n| 16|          27MC|       Roxo|      Platinum|        1|        B|\n| 17|          25FD|      Verde|         Black|        1|        A|\n| 18|          28MD|      Cinza|    Black-Beta|        0|        C|\n| 19|          27MD|    Amarelo|Platinum-Alpha|        1|        C|\n| 20|          25FV|    Amarelo|      Platinum|        1|        A|\n+---+--------------+-----------+--------------+---------+---------+\nonly showing top 20 rows\n\n"}], "source": "import pyspark.sql.functions as F\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\nfrom pyspark.sql.functions import concat_ws\nfrom pyspark.sql.functions import split, col \nfrom os.path import abspath\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Abrindo uma sess\u00e3o Spark\nspark = (SparkSession.builder\n         .appName(\"Estudando PySpark\")\n         .enableHiveSupport() \n         .getOrCreate())\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Criando um schema para definir os tipos de preenchimento para o df\nschema = StructType([ \\\n    StructField(\"ID\", IntegerType(), True), \\\n    StructField(\"CHAVE_SITUACAO\", StringType(), True), \\\n    StructField(\"CLASS_RISCO\",StringType(),True), \\\n    StructField(\"CAT_CLIENTE\",StringType(),True), \\\n    StructField(\"PAGAMENTO\",IntegerType(),True),  \\\n    StructField(\"CATEGORIA\",StringType(),True), \\\n  ])\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Criando um df a partir de um arquivo csv\ndf = (spark.read \n    .options(header=True, delimiter=\",\")\n    .schema(schema)\n    .csv(\"gs://official-bucket-01/ChavesClientes-_1_.csv\"))\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Tratando as colunas na tabela\ndf = df.select(\"ID\", \"CHAVE_SITUACAO\", \"CLASS_RISCO\", \"CAT_CLIENTE\", \"PAGAMENTO\", F.regexp_replace(F.col(\"CLASS_RISCO\"), \"[-+]\", \"\").alias(\"CLASS_RISCO_REPLACE\"))\ndf = df.withColumn(\"CATEGORIA\", df.CLASS_RISCO.substr(0,1))\ndf = df.withColumn(\"CLASS_RISCO\", df.CLASS_RISCO_REPLACE.substr(2,30))\ndf = df.select(\"ID\", \"CHAVE_SITUACAO\", \"CLASS_RISCO\", \"CAT_CLIENTE\", \"PAGAMENTO\", \"CATEGORIA\")\n"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+--------------+-----------+--------------+---------+---------+\n| ID|CHAVE_SITUACAO|CLASS_RISCO|   CAT_CLIENTE|PAGAMENTO|CATEGORIA|\n+---+--------------+-----------+--------------+---------+---------+\n|  1|          32FC|      cinza|   Basic-Alpha|        1|        C|\n|  2|          25MV|    Amarelo|         Black|        1|        A|\n|  3|          27MV|    Amarelo|    Basic-Beta|        1|        B|\n|  4|          26FD|    Amarelo|         Black|        0|        B|\n|  5|          26FD|    Amarelo|         Black|        0|        C|\n|  6|          28FC|    Amarelo|Platinum-Alpha|        0|        C|\n|  7|          27MD|      Verde| Platinum-Beta|        1|        A|\n|  8|          31MD|      Cinza|         Basic|        0|        C|\n|  9|          28FS|      Cinza|         Black|        1|        A|\n| 10|          31MV|    Amarelo|      Platinum|        1|        C|\n| 11|          29MV|    Amarelo|         Basic|        1|        A|\n| 12|          30FC|      Cinza|    Basic-Beta|        0|        C|\n| 13|          28FC|      verde|         Basic|        0|        B|\n| 14|          26MC|      Verde|      Platinum|        1|        A|\n| 15|          26MC|       roxo|   Black-Alpha|        1|        C|\n| 16|          27MC|       Roxo|      Platinum|        1|        B|\n| 17|          25FD|      Verde|         Black|        1|        A|\n| 18|          28MD|      Cinza|    Black-Beta|        0|        C|\n| 19|          27MD|    Amarelo|Platinum-Alpha|        1|        C|\n| 20|          25FV|    Amarelo|      Platinum|        1|        A|\n+---+--------------+-----------+--------------+---------+---------+\nonly showing top 20 rows\n\n"}], "source": "df.show()\n"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "\ndf.write.insertInto('clientes.chaves_clientes', overwrite=False)\n\n"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "StructType(List(StructField(ID,IntegerType,true),StructField(CHAVE_SITUACAO,StringType,true),StructField(CLASS_RISCO,StringType,true),StructField(CAT_CLIENTE,StringType,true),StructField(PAGAMENTO,IntegerType,true),StructField(CATEGORIA,StringType,true)))\n+---+--------------+-----------+--------------+---------+---------+\n| ID|CHAVE_SITUACAO|CLASS_RISCO|   CAT_CLIENTE|PAGAMENTO|CATEGORIA|\n+---+--------------+-----------+--------------+---------+---------+\n|  1|          32FC|      cinza|   Basic-Alpha|        1|        C|\n|  2|          25MV|    Amarelo|         Black|        1|        A|\n|  3|          27MV|    Amarelo|    Basic-Beta|        1|        B|\n|  4|          26FD|    Amarelo|         Black|        0|        B|\n|  5|          26FD|    Amarelo|         Black|        0|        C|\n|  6|          28FC|    Amarelo|Platinum-Alpha|        0|        C|\n|  7|          27MD|      Verde| Platinum-Beta|        1|        A|\n|  8|          31MD|      Cinza|         Basic|        0|        C|\n|  9|          28FS|      Cinza|         Black|        1|        A|\n| 10|          31MV|    Amarelo|      Platinum|        1|        C|\n| 11|          29MV|    Amarelo|         Basic|        1|        A|\n| 12|          30FC|      Cinza|    Basic-Beta|        0|        C|\n| 13|          28FC|      verde|         Basic|        0|        B|\n| 14|          26MC|      Verde|      Platinum|        1|        A|\n| 15|          26MC|       roxo|   Black-Alpha|        1|        C|\n| 16|          27MC|       Roxo|      Platinum|        1|        B|\n| 17|          25FD|      Verde|         Black|        1|        A|\n| 18|          28MD|      Cinza|    Black-Beta|        0|        C|\n| 19|          27MD|    Amarelo|Platinum-Alpha|        1|        C|\n| 20|          25FV|    Amarelo|      Platinum|        1|        A|\n+---+--------------+-----------+--------------+---------+---------+\nonly showing top 20 rows\n\n"}], "source": "df_hive = spark.sql(\"select * from clientes.chaves_clientes\")\nprint(df.schema)\ndf.show()"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}